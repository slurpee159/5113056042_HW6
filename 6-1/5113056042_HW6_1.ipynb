{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FaB4zmKnONfJ",
        "outputId": "c95bcb20-2630-4159-8c06-13743e5cd45d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Face-Mask-Detection' already exists and is not an empty directory.\n",
            "Found 3274 images belonging to 2 classes.\n",
            "Found 818 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input, decode_predictions\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "import requests\n",
        "from PIL import Image\n",
        "import io\n",
        "\n",
        "# Step 1: Build VGG16 Pretrained Model\n",
        "def build_vgg16_model():\n",
        "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    # Add custom layers\n",
        "    x = Flatten()(base_model.output)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    predictions = Dense(2, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "model = build_vgg16_model()\n",
        "\n",
        "# Step 2: Modify the code to use Medical Mask Dataset\n",
        "# Clone the Medical Mask dataset if not already cloned\n",
        "!git clone https://github.com/chandrikadeb7/Face-Mask-Detection.git\n",
        "\n",
        "def load_dataset():\n",
        "    data_gen = ImageDataGenerator(\n",
        "        rescale=1.0/255,\n",
        "        validation_split=0.2,\n",
        "    )\n",
        "\n",
        "    # Set the correct dataset path\n",
        "    dataset_path = 'Face-Mask-Detection/dataset'  # Adjust based on the repo structure\n",
        "\n",
        "    train_data = data_gen.flow_from_directory(\n",
        "        dataset_path,\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical',\n",
        "        subset='training'\n",
        "    )\n",
        "\n",
        "    val_data = data_gen.flow_from_directory(\n",
        "        dataset_path,\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical',\n",
        "        subset='validation'\n",
        "    )\n",
        "    return train_data, val_data\n",
        "\n",
        "train_dataset, val_dataset = load_dataset()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_data, val_data, epochs=2):\n",
        "    model.fit(train_data, validation_data=val_data, epochs=epochs)\n",
        "    return model\n",
        "\n",
        "model = train_model(model, train_dataset, val_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAnnI72W0T3i",
        "outputId": "aef8b4f4-74af-470a-d4ae-11493117a457"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m 37/103\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m19:29\u001b[0m 18s/step - accuracy: 0.7425 - loss: 1.2557"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2273s\u001b[0m 22s/step - accuracy: 0.8495 - loss: 0.6891 - val_accuracy: 0.9584 - val_loss: 0.0843\n",
            "Epoch 2/2\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2257s\u001b[0m 22s/step - accuracy: 0.9956 - loss: 0.0185 - val_accuracy: 0.9939 - val_loss: 0.0261\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Classify image from local path\n",
        "def test_image_from_local(image_path, model, class_names):\n",
        "    try:\n",
        "        # Load image from local file\n",
        "        img = Image.open(image_path).convert('RGB')\n",
        "        img = img.resize((224, 224))\n",
        "\n",
        "        img_array = image.img_to_array(img)\n",
        "        img_array = np.expand_dims(img_array, axis=0)\n",
        "        img_array = preprocess_input(img_array)\n",
        "\n",
        "        predictions = model.predict(img_array)\n",
        "        predicted_class = class_names[np.argmax(predictions)]\n",
        "        print(f\"Predicted class: {predicted_class}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "\n",
        "# Example usage for local image\n",
        "test_image_path = r\"/content/images/1.jpg\"\n",
        "test_image_from_local(test_image_path, model, ['with_mask', 'without_mask'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gH4099c60bAe",
        "outputId": "0afc1931-063c-408e-8641-e865dfb45257"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 884ms/step\n",
            "Predicted class: with_mask\n"
          ]
        }
      ]
    }
  ]
}